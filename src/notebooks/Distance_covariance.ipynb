{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "@njit\n",
    "def dcov_cb(x:np.float32,y:np.bool8):\n",
    "    \"\"\"\n",
    "    Oleg Kanakov implementation of distance covariance\n",
    "    22 Feb 2023\n",
    "    Same as dcor library for binary outcome variable (y) \n",
    "    Time complexity is O(n), n = len(x) = len(y)\n",
    "    x must be sorted before, y_i should corresponds to x_i\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError('Array lengths do not match!')\n",
    "\n",
    "    N=x.size\n",
    "    \n",
    "    n=0; nw=0\n",
    "    z=0.; zw=0.\n",
    "    d=0.\n",
    "    for i in range(N):\n",
    "        if y[i]==True:\n",
    "            d += x[i]*nw-zw\n",
    "            n += 1\n",
    "            z += x[i]\n",
    "        else:\n",
    "            d  += x[i]*n-z\n",
    "            nw += 1\n",
    "            zw += x[i]\n",
    "\n",
    "    qN=nw; pN=n\n",
    "    sx=z+zw\n",
    "\n",
    "    add=0.\n",
    "    sab=0.\n",
    "    s=0.\n",
    "    for i in range(N):\n",
    "        aid = -(N-2.*i)*x[i] -2.*s +sx\n",
    "        s += x[i]\n",
    "        if y[i]==True:\n",
    "            bid = qN\n",
    "        else:\n",
    "            bid = pN\n",
    "        \n",
    "        add += aid\n",
    "        sab += aid*bid\n",
    "\n",
    "    bdd = 2.*qN*pN\n",
    "\n",
    "    return 2.*d/N**2. - 2.*sab/N**3. + add*bdd/N**4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def dcor_cb(x:np.float32,y:np.bool8):\n",
    "    \"\"\"\n",
    "    Oleg Kanakov implementation of distance correlation\n",
    "    22 Feb 2023\n",
    "    Same as dcor library for binary outcome variable (y) \n",
    "    Time complexity is O(n), n = len(x) = len(y)\n",
    "    x must be sorted before, y_i should corresponds to x_i\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError('Array lengths do not match!')\n",
    "\n",
    "    N=x.size\n",
    "    \n",
    "    n=0; nw=0\n",
    "    z=0.; zw=0.\n",
    "    d=0.\n",
    "    sx2=0.\n",
    "    for i in range(N):\n",
    "        sx2 += x[i]*x[i]\n",
    "        if y[i]==True:\n",
    "            d += x[i]*nw-zw\n",
    "            n += 1\n",
    "            z += x[i]\n",
    "        else:\n",
    "            d  += x[i]*n-z\n",
    "            nw += 1\n",
    "            zw += x[i]\n",
    "\n",
    "    qN=nw; pN=n\n",
    "    sx=z+zw\n",
    "    \n",
    "    add=0.\n",
    "    sab=0.\n",
    "    sai2=0.\n",
    "    s=0.\n",
    "    for i in range(N):\n",
    "        aid = -(N-2.*i)*x[i] -2.*s +sx\n",
    "        s += x[i]\n",
    "        if y[i]==True:\n",
    "            bid = qN\n",
    "        else:\n",
    "            bid = pN\n",
    "        \n",
    "        add += aid\n",
    "        sai2 += aid*aid\n",
    "        sab += aid*bid\n",
    "\n",
    "    bdd = 2.*qN*pN\n",
    "\n",
    "    dxx = 2.*(N*sx2-sx*sx)\n",
    "    \n",
    "    dcov = 2.*d/N**2. - 2.*sab/N**3. + add*bdd/N**4.\n",
    "    dcovxx = dxx/N**2. -2.*sai2/N**3. + add*add/N**4.\n",
    "    dcovyy = bdd*bdd/N**4.\n",
    "\n",
    "    return dcov/(dcovxx*dcovyy)**0.5 \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000000;\n",
    "x = np.random.uniform(0,1,N)\n",
    "y = (x + np.random.normal(0,0.2,N)) > 0.95\n",
    "ysur1 = np.roll(y,100) # time-shifted \"surrogate\"\n",
    "ysur2 = np.roll(y,200) # another one\n",
    "k = np.argsort(x) # find sorting permutation\n",
    "x = x[k]\n",
    "y = y[k]\n",
    "ysur1 = ysur1[k]\n",
    "ysur2 = ysur2[k]\n",
    "del k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18972462796801534"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcor_cb(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5658451970047904e-06"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcor_cb(x,ysur1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.737465220168448e-07"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcor_cb(x,ysur2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007626302076594704"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dcor\n",
    "\n",
    "dcor.distance_covariance_sqr(x.astype(np.float64),y.astype(np.float64),method='avl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0076263020765869605"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcor.distance_covariance_sqr(x.astype(np.float64),y.astype(np.float64),method='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18972462796827202"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcor.distance_correlation_sqr(x.astype(np.float64),y.astype(np.float64),method='mergesort')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclone test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using matplotlib backend: QtAgg\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "%matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import textwrap\n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy import stats\n",
    "import scipy\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid', {'legend.frameon':True})\n",
    "sns.set_palette(sns.color_palette(\"Set1\", 12))\n",
    "#sns.set_context(\"paper\")\n",
    "fontsize = 12\n",
    "params = {'legend.fontsize': fontsize,\n",
    "  'figure.figsize': (18, 15),\n",
    "  'axes.labelsize': fontsize,\n",
    "  'axes.titlesize':fontsize,\n",
    "  'axes.edgecolor':\"0.3\",\n",
    "  'xtick.labelsize':fontsize,\n",
    "  'ytick.labelsize':fontsize,\n",
    "  'legend.fontsize':10,\n",
    "  'font.size':fontsize,\n",
    "  'font.family':'serif'}\n",
    "pylab.rcParams.update(params)\n",
    "plt.rc('axes', labelsize=fontsize) \n",
    "\n",
    "#plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from pathlib2 import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from metric_store import save_metrics, save_metric, load_metrics, get_metric_names, load_metric\n",
    "from network_metrics import prepare_metric\n",
    "from pipeline.pipeline import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = \"pipeline.config\"\n",
    "config = load_config(config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corr_network import load_data, get_available_mask\n",
    "data = load_data(config)\n",
    "available_mask = get_available_mask(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability_for_metrics/network_metrics/LCC_0.95 (36, 69, 113960)\n"
     ]
    }
   ],
   "source": [
    "metric_names = [\n",
    "    #'input_data/MSLP_preproc',\n",
    "    #'probability_for_metrics/input_data/MSLP',\n",
    "    #'probability_for_metrics/input_data/MSLP_preproc',\n",
    "    #'probability_for_metrics/network_metrics/LCC_w',\n",
    "    #'probability_for_metrics/network_metrics/LCC_0.9',\n",
    "    'probability_for_metrics/network_metrics/LCC_0.95',\n",
    "]\n",
    "for metric_name in metric_names:\n",
    "    config.metrics_plot_options['metric_name'] = metric_name\n",
    "    metric = load_metric(config, metric_name)\n",
    "    metric = prepare_metric(metric_name, metric, available_mask)\n",
    "    print(metric_name, metric.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['network_metrics/LCC_w',\n",
       " 'network_metrics/GCC_w',\n",
       " 'network_metrics/degree_w',\n",
       " 'network_metrics/EVC_w',\n",
       " 'network_metrics/closeness_w',\n",
       " 'network_metrics/LCC_0.9',\n",
       " 'network_metrics/GCC_0.9',\n",
       " 'network_metrics/degree_0.9',\n",
       " 'network_metrics/EVC_0.9',\n",
       " 'network_metrics/closeness_0.9',\n",
       " 'network_metrics/LCC_0.95',\n",
       " 'network_metrics/GCC_0.95',\n",
       " 'network_metrics/degree_0.95',\n",
       " 'network_metrics/EVC_0.95',\n",
       " 'network_metrics/closeness_0.95']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'network_metrics'\n",
    "metric_names = list(get_metric_names(config, prefix = prefix).keys())\n",
    "metric_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sond/probability_for_metrics/network_metrics/LCC_w',\n",
       " 'sond/probability_for_metrics/network_metrics/degree_w',\n",
       " 'sond/probability_for_metrics/network_metrics/EVC_w',\n",
       " 'sond/probability_for_metrics/network_metrics/closeness_w',\n",
       " 'sond/probability_for_metrics/network_metrics/LCC_0.9',\n",
       " 'sond/probability_for_metrics/network_metrics/degree_0.9',\n",
       " 'sond/probability_for_metrics/network_metrics/EVC_0.9',\n",
       " 'sond/probability_for_metrics/network_metrics/closeness_0.9',\n",
       " 'sond/probability_for_metrics/network_metrics/LCC_0.95',\n",
       " 'sond/probability_for_metrics/network_metrics/degree_0.95',\n",
       " 'sond/probability_for_metrics/network_metrics/EVC_0.95',\n",
       " 'sond/probability_for_metrics/network_metrics/closeness_0.95',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/LCC_w',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/degree_w',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/EVC_w',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/closeness_w',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/LCC_0.9',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/degree_0.9',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/EVC_0.9',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/closeness_0.9',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/LCC_0.95',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/degree_0.95',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/EVC_0.95',\n",
       " 'sond/probability_for_metrics/diff_metrics/network_metrics/closeness_0.95']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'sond'\n",
    "metric_names = list(get_metric_names(config, prefix = prefix).keys())\n",
    "metric_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_events = np.load('../cyclones_events.npz')['cyclone_events_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_network_metrics.utils import get_times_lats_lots\n",
    "from plot_network_metrics.utils import get_sond_times\n",
    "\n",
    "all_times, all_lats, all_lons = get_times_lats_lots(config)\n",
    "sond_time_inds = get_sond_times(config, all_times)\n",
    "cyclone_events_sond = cyclone_events[:, :, sond_time_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def compute_rolled_dcor(metric, cyclone_events, roll_shift=1):\n",
    "    is_ok = ~np.isnan(metric)\n",
    "    cyclone_events_rolled = cyclone_events.copy()\n",
    "    x = metric[is_ok].astype('float32')\n",
    "    ids = np.argsort(x)\n",
    "    xs = x[ids]\n",
    "\n",
    "    start_dcor = None\n",
    "    dcor_counts = [0, 0]\n",
    "\n",
    "    dcor_on_roll = []\n",
    "    rolls = []\n",
    "    cur_roll = 0\n",
    "\n",
    "    nt = metric.shape[2]\n",
    "    \n",
    "    tqdm_traverse = tqdm(range(nt // roll_shift))\n",
    "\n",
    "    for id_roll in tqdm_traverse:\n",
    "        y = cyclone_events_rolled[is_ok]\n",
    "        ys = y[ids]\n",
    "\n",
    "        cur_dcor = dcor_cb(xs, ys)\n",
    "        if start_dcor is None:\n",
    "            start_dcor = cur_dcor\n",
    "        else:\n",
    "            dcor_counts[cur_dcor < start_dcor] += 1\n",
    "        dcor_on_roll += [cur_dcor]\n",
    "        rolls += [cur_roll]\n",
    "        \n",
    "        pv = dcor_counts[1] / max(1, dcor_counts[0] + dcor_counts[1])\n",
    "\n",
    "        description = f\"{start_dcor:0.3g} > {cur_dcor:0.3g}. | \"\n",
    "        description += f\"{dcor_counts[0]} + {dcor_counts[1]} = {dcor_counts[0] + dcor_counts[1]}. | \"\n",
    "        description += f\"p-value = {pv:0.3g}\"\n",
    "        tqdm_traverse.set_description(description)\n",
    "\n",
    "        cyclone_events_rolled = np.roll(cyclone_events_rolled, roll_shift)\n",
    "        cur_roll += roll_shift\n",
    "    roll_hours = np.array(rolls) * 3\n",
    "    df_dcor_rolls = pd.DataFrame({\n",
    "        'roll': rolls, \n",
    "        'roll_hours': roll_hours, \n",
    "        'dcor': dcor_on_roll\n",
    "    })\n",
    "    return df_dcor_rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sond/probability_for_metrics/network_metrics/LCC_w', 'sond/probability_for_metrics/network_metrics/LCC_0.9', 'sond/probability_for_metrics/network_metrics/LCC_0.95']\n",
      "sond/probability_for_metrics/network_metrics/LCC_0.9 (36, 69, 38064)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f222784429344709a6842b290475abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4758 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sond/probability_for_metrics/network_metrics/LCC_0.95 (36, 69, 38064)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ac0e3028c04cf9ae49668df6bb5c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4758 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sond/probability_for_metrics/network_metrics/LCC_w (36, 69, 38064)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d462a2ff9da14a2a941fbebb157a1938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4758 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from metric_store import Metrics\n",
    "metric_names = [\n",
    "    #'input_data/MSLP_preproc',\n",
    "    #'probability_for_metrics/input_data/MSLP',\n",
    "    #'probability_for_metrics/input_data/MSLP_preproc',\n",
    "    'probability_for_metrics/network_metrics/LCC_w',\n",
    "    'probability_for_metrics/network_metrics/LCC_0.9',\n",
    "    'probability_for_metrics/network_metrics/LCC_0.95',\n",
    "]\n",
    "is_sond = True\n",
    "cyclone_events_selected = cyclone_events_sond.copy() if is_sond else cyclone_events.copy()\n",
    "if is_sond:\n",
    "    metric_names = ['sond/' + metric_name for metric_name in metric_names]\n",
    "print(metric_names)\n",
    "for metric_name, metric in Metrics(config, metric_names=metric_names):\n",
    "    metric = prepare_metric(metric_name, metric, available_mask)\n",
    "    print(metric_name, metric.shape)\n",
    "    df_dcor_rolls = compute_rolled_dcor(metric, cyclone_events_selected, roll_shift=8)\n",
    "    short_metric_name = metric_name.replace('/', '$')\n",
    "    file_name = config.distance_covariance_options['work_dir'] / f'dcor_{short_metric_name}.tsv'\n",
    "    file_name.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_dcor_rolls.to_csv(file_name, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('Z:/Research/Climate/data/ERA5/ERA5_MSL_1982_2020_3h_0.75/distance_covariance_window_2d_delay_0d/dcor_probability_for_metrics$network_metrics$LCC_0.95.tsv')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roll</th>\n",
       "      <th>roll_hours</th>\n",
       "      <th>dcor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.067696e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>2.378156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>1.945169e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "      <td>3.906063e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>96</td>\n",
       "      <td>4.516938e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>120</td>\n",
       "      <td>6.338086e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>144</td>\n",
       "      <td>2.077307e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56</td>\n",
       "      <td>168</td>\n",
       "      <td>1.423717e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>192</td>\n",
       "      <td>5.358369e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72</td>\n",
       "      <td>216</td>\n",
       "      <td>5.791252e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>80</td>\n",
       "      <td>240</td>\n",
       "      <td>1.704223e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>88</td>\n",
       "      <td>264</td>\n",
       "      <td>6.499805e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    roll  roll_hours          dcor\n",
       "0      0           0  2.067696e-04\n",
       "1      8          24  2.378156e-04\n",
       "2     16          48  1.945169e-04\n",
       "3     24          72  3.906063e-05\n",
       "4     32          96  4.516938e-06\n",
       "5     40         120  6.338086e-07\n",
       "6     48         144  2.077307e-07\n",
       "7     56         168  1.423717e-07\n",
       "8     64         192  5.358369e-07\n",
       "9     72         216  5.791252e-07\n",
       "10    80         240  1.704223e-07\n",
       "11    88         264  6.499805e-08"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dcor_rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = a[[1, 0]]\n",
    "b[0] = 7\n",
    "b\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float16')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCC_w\n",
    "# 0.000316 > 6.87e-07. | 0 + 87 = 87. | p-value = 1.0: 2%\n",
    "\n",
    "# LCC_0.9\n",
    "# 0.000224 > 6.46e-07. | 0 + 3560 = 3560. | p-value = 1.0: 100%\n",
    "\n",
    "# LCC_0.95\n",
    "# 0.000206 > 3.36e-07. 0 + 182 = 182 p-value = 1.0: 5%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8571e7f3e92f6e490cddd84ef78d4e4e0b96a1f565959148b10a39523fba88f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
