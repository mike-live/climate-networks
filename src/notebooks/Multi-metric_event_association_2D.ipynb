{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import re\n",
    "import time\n",
    "import textwrap\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib2 import Path\n",
    "import os\n",
    "import math\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import chi2_contingency\n",
    "from functools import partial\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid', {'legend.frameon':True})\n",
    "sns.set_palette(sns.color_palette(\"Set1\", 12))\n",
    "#sns.set_context(\"paper\")\n",
    "fontsize = 12\n",
    "params = {'legend.fontsize': fontsize,\n",
    "  'figure.figsize': (18, 15),\n",
    "  'axes.labelsize': fontsize,\n",
    "  'axes.titlesize':fontsize,\n",
    "  'axes.edgecolor':\"0.3\",\n",
    "  'xtick.labelsize':fontsize,\n",
    "  'ytick.labelsize':fontsize,\n",
    "  'legend.fontsize':10,\n",
    "  'font.size':fontsize,\n",
    "  'font.family':'serif'}\n",
    "pylab.rcParams.update(params)\n",
    "plt.rc('axes', labelsize=fontsize) \n",
    "#plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_2d_delay_0d\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from helpers import numba_config\n",
    "from metric_store import save_metrics, save_metric, load_metrics, get_metric_names, load_metric\n",
    "from corr_network import load_data, get_available_mask\n",
    "from network_metrics import prepare_metric\n",
    "from pipeline.pipeline import load_config\n",
    "from g_test_for_metrics.g_test_for_metrics import get_metric_indicators, get_sign_for_metric\n",
    "\n",
    "config_name = \"pipeline.config\"\n",
    "config = load_config(config_name)\n",
    "\n",
    "print(config.prefix_for_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "signs_metric = {\n",
    "    'probability_for_metrics/input_data/MSLP': False, \n",
    "    'probability_for_metrics/input_data/MSLP_preproc': False,\n",
    "    'probability_for_metrics/network_metrics/LCC_w': True, \n",
    "    'probability_for_metrics/network_metrics/degree_w': False, \n",
    "    'probability_for_metrics/network_metrics/EVC_w': False,\n",
    "    'probability_for_metrics/network_metrics/closeness_w': True,\n",
    "    'probability_for_metrics/network_metrics/LCC_0.9': True,\n",
    "    'probability_for_metrics/network_metrics/degree_0.9': False,\n",
    "    'probability_for_metrics/network_metrics/EVC_0.9': False,\n",
    "    'probability_for_metrics/network_metrics/closeness_0.9': False,\n",
    "    'probability_for_metrics/network_metrics/LCC_0.95': True,\n",
    "    'probability_for_metrics/network_metrics/degree_0.95': False,\n",
    "    'probability_for_metrics/network_metrics/EVC_0.95': False,\n",
    "    'probability_for_metrics/network_metrics/closeness_0.95': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_names_for_metric(metric_names):\n",
    "    full_metric_names = list(get_metric_names(config, prefix='probability_for_metrics').keys())\n",
    "    selected_metric_names = []\n",
    "    for name in metric_names:\n",
    "        for full_name in full_metric_names:\n",
    "            if full_name.endswith(name) and full_name.find('diff_metrics') == -1:\n",
    "                selected_metric_names += [full_name]\n",
    "                break\n",
    "    return selected_metric_names\n",
    "\n",
    "\n",
    "def special_loading_of_metrics(config, selected_metric_names):\n",
    "    metrics = []\n",
    "    for metric_name in selected_metric_names:\n",
    "        config.metrics_plot_options['metric_name'] = metric_name\n",
    "        metric = load_metric(config, metric_name).astype('float32')\n",
    "        metric = metric if signs_metric[metric_name] else 1 - metric\n",
    "        metric = -np.log10(metric + 1e-10)\n",
    "        metrics.append(metric)\n",
    "        print(metric_name, metric.shape)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_f1_score(fn, fp, tp):\n",
    "    if (tp == 0) and (fp == 0) and (fn == 0):\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        f1_score = (2 * tp) / (2 * tp + fp + fn)\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "def compute_balanced_accuracy(tn, fn, fp, tp):\n",
    "    if (tp + fn == 0) and (tn + fp == 0):\n",
    "        b_acc = 0\n",
    "    else:\n",
    "        b_acc = 0.5 * ((tp / (tp + fn)) + (tn / (tn + fp)))\n",
    "    return b_acc\n",
    "\n",
    "\n",
    "def compute_matthews_coefficient(tn, fn, fp, tp):\n",
    "    if (tp + fp == 0) or (tp + fn == 0) or (tn + fp == 0) or (tn + fn == 0):\n",
    "        mcc = 0\n",
    "    else:\n",
    "        denominator1 = math.sqrt(tp + fp) * math.sqrt(tp + fn)\n",
    "        denominator2 = math.sqrt(tn + fp) * math.sqrt(tn + fn)\n",
    "        mcc = ((tp / denominator1) * (tn / denominator2)) - ((fp / denominator1) * (fn / denominator2))\n",
    "    return mcc\n",
    "\n",
    "\n",
    "def compute_tpr_fpr_f1_bacc_mcc(contigency_table):\n",
    "    tn, fn, fp, tp = contigency_table.ravel()\n",
    "    tn, fn, fp, tp = map(float, [tn, fn, fp, tp])\n",
    "    \n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    f1 = compute_f1_score(fn, fp, tp)\n",
    "    bacc = compute_balanced_accuracy(tn, fn, fp, tp)\n",
    "    mcc = compute_matthews_coefficient(tn, fn, fp, tp)\n",
    "    \n",
    "    return tpr, fpr, f1, bacc, mcc\n",
    "\n",
    "\n",
    "def compute_weighted_sum(weights, metrics):\n",
    "    weighted_metric = metrics[0] * weights[0]\n",
    "    for i in range(1, len(metrics)):\n",
    "        weighted_metric += metrics[i] * weights[i]\n",
    "    return weighted_metric\n",
    "\n",
    "\n",
    "def compute_contigency_table(weights, metrics, cyclone_events):\n",
    "    metric_thr = 1\n",
    "    \n",
    "    weighted_metric = compute_weighted_sum(weights, metrics)\n",
    "    \n",
    "    predicted_events = (weighted_metric > metric_thr)\n",
    "    \n",
    "    not_nan_mask = ~np.isnan(weighted_metric)\n",
    "    tn = np.sum(~predicted_events & ~cyclone_events & not_nan_mask)\n",
    "    fn = np.sum(~predicted_events &  cyclone_events & not_nan_mask)\n",
    "    fp = np.sum( predicted_events & ~cyclone_events & not_nan_mask)\n",
    "    tp = np.sum( predicted_events &  cyclone_events & not_nan_mask)\n",
    "\n",
    "    return np.array([[tn, fn], [fp, tp]])\n",
    "\n",
    "\n",
    "def perform_g_test(contigency_table):\n",
    "    if ((contigency_table[0, 0] == 0) and (contigency_table[0, 1] == 0)) or ((contigency_table[1, 0] == 0) and (contigency_table[1, 1] == 0)):\n",
    "        I_stat = g_stat = 0\n",
    "        p_val = np.nan\n",
    "    else:\n",
    "        g_stat, p_val, dof, expctd = chi2_contingency(contigency_table, lambda_=\"log-likelihood\", correction=False)\n",
    "        I_stat = g_stat / contigency_table.flatten().sum() / 2\n",
    "    return g_stat, p_val, I_stat\n",
    "\n",
    "\n",
    "def compute_quality(weights, metrics, cyclone_events):\n",
    "    contigency_table = compute_contigency_table(weights, metrics, cyclone_events)\n",
    "    g_stat, _, _ = perform_g_test(contigency_table)    \n",
    "    return -g_stat\n",
    "\n",
    "\n",
    "print_initial = True\n",
    "def optimization(metrics, cyclone_events, number_random_iter=40, max_minimize_iter=500):\n",
    "    global print_initial\n",
    "    compute_quality_all = partial(compute_quality, metrics=metrics, cyclone_events=cyclone_events)\n",
    "    \n",
    "    def show_progress_pbar(x, pbar):\n",
    "        global print_initial\n",
    "\n",
    "        f = compute_quality_all(x)\n",
    "\n",
    "        if print_initial:\n",
    "            print(f\"initial g-stat = {-f:.2f}, initial x = {x}\")\n",
    "            print_initial = False\n",
    "\n",
    "        pbar.set_description(f\"current g-stat = {-f:.2f}, x = {x}\")\n",
    "        pbar.update(1)\n",
    "    \n",
    "    \n",
    "    pbar_for_random_iter = tqdm(range(0, number_random_iter))\n",
    "    \n",
    "    optimal_g_stat = sys.maxsize # большое положительное число\n",
    "    optimal_weights = []\n",
    "    for ri in pbar_for_random_iter:\n",
    "        pbar_for_random_iter.set_postfix({'random_iter #': ri+1})\n",
    "        random_initial_weights = np.random.uniform(0.0, 0.5, len(metrics))\n",
    "        if len(random_initial_weights) > 1:\n",
    "            random_initial_weights /= np.sum(random_initial_weights)\n",
    "        \n",
    "        \n",
    "        print_initial = True\n",
    "        show_minimize_progress = partial(show_progress_pbar, pbar=tqdm(total=max_minimize_iter))\n",
    "        result = minimize(compute_quality_all, random_initial_weights, bounds=[(0, 1)]*len(metrics), method='nelder-mead',\n",
    "                          options={'return_all': True, 'maxiter': max_minimize_iter}, callback=show_minimize_progress)\n",
    "        negative_g_stat = compute_quality(result.x, metrics, cyclone_events)\n",
    "        if negative_g_stat < optimal_g_stat:\n",
    "            optimal_g_stat = negative_g_stat\n",
    "            optimal_weights = result.x\n",
    "\n",
    "    return optimal_weights\n",
    "\n",
    "\n",
    "def calc_quality_metrics_for_optimal_combination(metrics, cyclone_events, optimal_weights):\n",
    "    contigency_table = compute_contigency_table(optimal_weights, metrics, cyclone_events)\n",
    "    g_stat, _, _ = perform_g_test(contigency_table)\n",
    "    tpr, fpr, f1, bacc, mcc = compute_tpr_fpr_f1_bacc_mcc(contigency_table)\n",
    "    return contigency_table, tpr, fpr, g_stat, f1, bacc, mcc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration_by_metrics(cyclone_events, base_metric, metrics_list, suff, track_sizes, number_random_iter, autosave=False, path=''):\n",
    "    result_dict = {}\n",
    "    metrics_rating = {str(key): [] for key in metrics_list}\n",
    "    ind = 0\n",
    "    for sub_metrics_list in metrics_list:\n",
    "        print('\\n', sub_metrics_list)\n",
    "        considered_metrics = [base_metric] + [f'{m}_{suff}' for m in sub_metrics_list]\n",
    "        considered_metrics = get_full_names_for_metric(considered_metrics)\n",
    "        print(considered_metrics)\n",
    "        \n",
    "        metrics = special_loading_of_metrics(config, considered_metrics)\n",
    "        \n",
    "        result_dict[f'subset{ind}'] = []\n",
    "        metrics_rating[str(sub_metrics_list)] = []\n",
    "        for track_size in track_sizes:\n",
    "            print(f'track_size={track_size}')\n",
    "            cyclone_events_ts = cyclone_events[f'cyclone_events_{track_size}']\n",
    "            optimal_weights = optimization(metrics, cyclone_events_ts, number_random_iter)\n",
    "            contigency_table, tpr, fpr, g_stat, f1, bacc, mcc = calc_quality_metrics_for_optimal_combination(metrics, \n",
    "                                                                                                             cyclone_events_ts,\n",
    "                                                                                                             optimal_weights)\n",
    "            result_dict[f'subset{ind}'].append([considered_metrics, track_size, optimal_weights.tolist(),\n",
    "                                                contigency_table.tolist(), tpr, fpr, g_stat, f1, bacc, mcc])\n",
    "\n",
    "            metrics_rating[str(sub_metrics_list)].append(g_stat)\n",
    "        \n",
    "            if autosave:\n",
    "                f = open(f'{path}/temp_file.txt','w')\n",
    "                f.write(str(result_dict))\n",
    "                f.close()\n",
    "\n",
    "                \n",
    "        metrics_rating[str(sub_metrics_list)] = np.mean(metrics_rating[str(sub_metrics_list)])  \n",
    "        ind += 1\n",
    "    \n",
    "    return result_dict, metrics_rating\n",
    "\n",
    "\n",
    "def save_optimization_results(result_dict, file_name):\n",
    "    writer = ExcelWriter(file_name)\n",
    "    \n",
    "    for key in result_dict:\n",
    "        result_arr = np.array(result_dict[key], dtype=object)\n",
    "        result_df = pd.DataFrame(result_arr.reshape(result_arr.shape[0], result_arr.shape[1]),\n",
    "                                 columns=['metrics_subset', 'track_size', 'weights', 'CT', 'TPR', 'FPR', 'g_stat', 'f1', 'bacc', 'mcc'],\n",
    "                                dtype=object)\n",
    "        result_df.to_excel(writer, sheet_name=key, index=False)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "number_random_iter = 40\n",
    "\n",
    "base_metric = 'MSLP_preproc'  # MSLP or MSLP_preproc\n",
    "suff = 'w'                    # 'w' or '0.9' or '0.95'\n",
    "network_metrics_1 = [['LCC'], ['degree'], ['closeness'], ['EVC']]\n",
    "\n",
    "\n",
    "cyclone_events = np.load('../cyclones_events.npz')\n",
    "\n",
    "global_path = 'D:/Climate/GitRep/climate-networks/src/ERA5/ERA5_MSL_1982_2020_3h_0.75/results_land_masked_and_preproc_window_2d_delay_0d/ea2D'  \n",
    "\n",
    "folder = f'{base_metric}_and_metrics_{suff}'\n",
    "path = f'{global_path}/{folder}'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "    \n",
    "# Only base_metric\n",
    "file_name = f'{path}/ea2D_{base_metric}.xlsx'\n",
    "result_dict, _ = iteration_by_metrics(cyclone_events, base_metric, [''], '', range(2, 14, 2), number_random_iter)\n",
    "print(result_dict)\n",
    "save_optimization_results(result_dict, file_name)\n",
    "\n",
    "# MSLP + one metric\n",
    "file_name = f'{path}/ea2D_{base_metric}_1metric_{suff}.xlsx'\n",
    "result_dict, metrics_rating = iteration_by_metrics(cyclone_events, base_metric, network_metrics_1, suff, range(2, 14, 2), \n",
    "                                                   number_random_iter, True, path)\n",
    "print(result_dict)\n",
    "save_optimization_results(result_dict, file_name)\n",
    "\n",
    "# MSLP + metrics\n",
    "file_name = f'{path}/ea2D_{base_metric}_metrics_{suff}.xlsx'\n",
    "metrics_priority = sorted(metrics_rating, key=metrics_rating.get, reverse=True)\n",
    "metrics_priority = [eval(m)[0] for m in metrics_priority]\n",
    "pd.DataFrame({'metrics_priority': metrics_priority}).to_csv(f'{file_name.split(\".xlsx\")[0]}_metrics_order.txt', index=False)\n",
    "print('metrics_priority:', metrics_priority)\n",
    "network_metrics_2 = [metrics_priority[0:2+i] for i in range(0, len(metrics_priority)-1)]\n",
    "print(network_metrics_2)\n",
    "result_dict, _ = iteration_by_metrics(cyclone_events, base_metric, network_metrics_2, suff, range(2, 14, 2), \n",
    "                                      number_random_iter, True, path)\n",
    "print(result_dict)\n",
    "save_optimization_results(result_dict, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
