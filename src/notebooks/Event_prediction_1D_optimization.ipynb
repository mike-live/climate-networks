{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e15452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import re\n",
    "import time\n",
    "import textwrap\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib2 import Path\n",
    "import os\n",
    "import math\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import chi2_contingency\n",
    "from functools import partial\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid', {'legend.frameon':True})\n",
    "sns.set_palette(sns.color_palette(\"Set1\", 12))\n",
    "#sns.set_context(\"paper\")\n",
    "fontsize = 12\n",
    "params = {'legend.fontsize': fontsize,\n",
    "  'figure.figsize': (18, 15),\n",
    "  'axes.labelsize': fontsize,\n",
    "  'axes.titlesize':fontsize,\n",
    "  'axes.edgecolor':\"0.3\",\n",
    "  'xtick.labelsize':fontsize,\n",
    "  'ytick.labelsize':fontsize,\n",
    "  'legend.fontsize':10,\n",
    "  'font.size':fontsize,\n",
    "  'font.family':'serif'}\n",
    "pylab.rcParams.update(params)\n",
    "plt.rc('axes', labelsize=fontsize) \n",
    "#plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6e1b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_2d_delay_0d\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from helpers import numba_config\n",
    "from metric_store import save_metrics, save_metric, load_metrics, get_metric_names, load_metric\n",
    "from corr_network import load_data, get_available_mask\n",
    "from network_metrics import prepare_metric\n",
    "from pipeline.pipeline import load_config\n",
    "from g_test_for_metrics.g_test_for_metrics import get_metric_indicators, get_sign_for_metric\n",
    "\n",
    "config_name = \"pipeline.config\"\n",
    "config = load_config(config_name)\n",
    "\n",
    "print(config.prefix_for_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ba35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs_metric = {\n",
    "    'probability_for_metrics/input_data/MSLP': False, \n",
    "    'probability_for_metrics/input_data/MSLP_preproc': False,\n",
    "    'probability_for_metrics/network_metrics/LCC_w': True, \n",
    "    'probability_for_metrics/network_metrics/degree_w': False, \n",
    "    'probability_for_metrics/network_metrics/EVC_w': False,\n",
    "    'probability_for_metrics/network_metrics/closeness_w': True,\n",
    "    'probability_for_metrics/network_metrics/LCC_0.9': True,\n",
    "    'probability_for_metrics/network_metrics/degree_0.9': False,\n",
    "    'probability_for_metrics/network_metrics/EVC_0.9': False,\n",
    "    'probability_for_metrics/network_metrics/closeness_0.9': False,\n",
    "    'probability_for_metrics/network_metrics/LCC_0.95': True,\n",
    "    'probability_for_metrics/network_metrics/degree_0.95': False,\n",
    "    'probability_for_metrics/network_metrics/EVC_0.95': False,\n",
    "    'probability_for_metrics/network_metrics/closeness_0.95': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aeda32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_names_for_metric(metric_names):\n",
    "    full_metric_names = list(get_metric_names(config, prefix='probability_for_metrics').keys())\n",
    "    selected_metric_names = []\n",
    "    for name in metric_names:\n",
    "        for full_name in full_metric_names:\n",
    "            if full_name.endswith(name) and full_name.find('diff_metrics') == -1:\n",
    "                selected_metric_names += [full_name]\n",
    "                break\n",
    "    return selected_metric_names\n",
    "\n",
    "\n",
    "def special_loading_of_metrics(config, selected_metric_names):\n",
    "    metrics = []\n",
    "    for metric_name in selected_metric_names:\n",
    "        config.metrics_plot_options['metric_name'] = metric_name\n",
    "        metric = load_metric(config, metric_name).astype('float32')\n",
    "        metric = metric if signs_metric[metric_name] else 1 - metric\n",
    "        metric = -np.log10(metric + 1e-10)\n",
    "        metrics.append(metric)\n",
    "        print(metric_name, metric.shape)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_f1_score(fn, fp, tp):\n",
    "    if (tp == 0) and (fp == 0) and (fn == 0):\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        f1_score = (2 * tp) / (2 * tp + fp + fn)\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "def compute_balanced_accuracy(tn, fn, fp, tp):\n",
    "    if (tp + fn == 0) and (tn + fp == 0):\n",
    "        b_acc = 0\n",
    "    else:\n",
    "        b_acc = 0.5 * ((tp / (tp + fn)) + (tn / (tn + fp)))\n",
    "    return b_acc\n",
    "\n",
    "\n",
    "def compute_matthews_coefficient(tn, fn, fp, tp):\n",
    "    if (tp + fp == 0) or (tp + fn == 0) or (tn + fp == 0) or (tn + fn == 0):\n",
    "        mcc = 0\n",
    "    else:\n",
    "        denominator1 = math.sqrt(tp + fp) * math.sqrt(tp + fn)\n",
    "        denominator2 = math.sqrt(tn + fp) * math.sqrt(tn + fn)\n",
    "        mcc = ((tp / denominator1) * (tn / denominator2)) - ((fp / denominator1) * (fn / denominator2))\n",
    "    return mcc\n",
    "\n",
    "\n",
    "def compute_tpr_fpr_f1_bacc_mcc(contigency_table):\n",
    "    tn, fn, fp, tp = contigency_table.ravel()\n",
    "    tn, fn, fp, tp = map(float, [tn, fn, fp, tp])\n",
    "    \n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    f1 = compute_f1_score(fn, fp, tp)\n",
    "    bacc = compute_balanced_accuracy(tn, fn, fp, tp)\n",
    "    mcc = compute_matthews_coefficient(tn, fn, fp, tp)\n",
    "    \n",
    "    return tpr, fpr, f1, bacc, mcc\n",
    "\n",
    "\n",
    "@jit(nopython = numba_config.nopython, nogil=numba_config.nogil, cache=numba_config.cache, error_model=\"numpy\")\n",
    "def estimate_prediction(predicted_events_1d, cyclone_events_1d, w):\n",
    "    cyclone_events_1d_start = np.zeros_like(cyclone_events_1d)\n",
    "    nt = len(predicted_events_1d)\n",
    "    blocked = np.zeros_like(predicted_events_1d)\n",
    "    for i in range(1, nt):\n",
    "        if cyclone_events_1d[i] > 0:\n",
    "            if cyclone_events_1d[i - 1] == 0:\n",
    "                cyclone_events_1d_start[i] = 1\n",
    "            else:\n",
    "                blocked[i] = 1\n",
    "    # Blocked is 1 if cyclone already started\n",
    "    # Blocked is 1 if cyclone was predicted in this moment\n",
    "    tn, fn, fp, tp = 0, 0, 0, 0\n",
    "    for i in range(nt):\n",
    "        if predicted_events_1d[i]:\n",
    "            if not blocked[i]:\n",
    "                if np.any(cyclone_events_1d_start[i:i + w]):\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "                blocked[i:i + w] = 1\n",
    "        else:\n",
    "            if not blocked[i]:\n",
    "                if np.any(cyclone_events_1d_start[i:i + w]):\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "                \n",
    "    tn //= w\n",
    "    fn //= w\n",
    "    \n",
    "    contigency_table = np.array([[tn, fn], [fp, tp]])\n",
    "    \n",
    "    return contigency_table\n",
    "\n",
    "\n",
    "def perform_g_test(contigency_table):\n",
    "    if ((contigency_table[0, 0] == 0) and (contigency_table[0, 1] == 0)) or ((contigency_table[1, 0] == 0) and (contigency_table[1, 1] == 0)):\n",
    "        I_stat = g_stat = 0\n",
    "        p_val = np.nan\n",
    "    else:\n",
    "        g_stat, p_val, dof, expctd = chi2_contingency(contigency_table, lambda_=\"log-likelihood\", correction=False)\n",
    "        I_stat = g_stat / contigency_table.flatten().sum() / 2\n",
    "    return g_stat, p_val, I_stat\n",
    "\n",
    "\n",
    "def compute_weighted_sum(weights, metrics):\n",
    "    weighted_metric = metrics[0] * weights[0]\n",
    "    for i in range(1, len(metrics)):\n",
    "        weighted_metric += metrics[i] * weights[i]\n",
    "    return weighted_metric\n",
    "\n",
    "\n",
    "def compute_contigency_table(weights, metrics, cyclone_events, window):\n",
    "    metric_thr = 1\n",
    "    weighted_metric = compute_weighted_sum(weights, metrics)\n",
    "    predicted_events = (weighted_metric > metric_thr)\n",
    "    predicted_events_1d = predicted_events.sum(axis=(0, 1))\n",
    "    cyclone_events_1d = cyclone_events.sum(axis=(0, 1))\n",
    "    contigency_table = estimate_prediction(predicted_events_1d, cyclone_events_1d, w=window)\n",
    "    return contigency_table\n",
    "\n",
    "\n",
    "def compute_quality_1(weights, metrics, cyclone_events, window):\n",
    "    contigency_table = compute_contigency_table(weights, metrics, cyclone_events, window)\n",
    "    g_stat, _, _ = perform_g_test(contigency_table)    \n",
    "    return -g_stat\n",
    "\n",
    "def get_tau_n_quality(contigency_table):\n",
    "    (tn, fn), (fp, tp) = contigency_table\n",
    "    quality = 1 - (fn / (fn + tp) + (fp + tp) / (fp + tn + tp + fn))\n",
    "    return quality\n",
    "    \n",
    "def compute_quality_2(weights, metrics, cyclone_events, window):\n",
    "    contigency_table = compute_contigency_table(weights, metrics, cyclone_events, window)\n",
    "    quality = get_tau_n_quality(contigency_table)\n",
    "    return -quality\n",
    "\n",
    "compute_quality = {'g_stat': compute_quality_1, 'tau_n_quality': compute_quality_2}\n",
    "\n",
    "print_initial = True\n",
    "def optimization(metrics, cyclone_events, window, quality_opt_func, number_random_iter=40, max_minimize_iter=500):\n",
    "    global print_initial\n",
    "    compute_quality_all = partial(compute_quality[quality_opt_func], metrics=metrics, cyclone_events=cyclone_events, window=window)\n",
    "    \n",
    "    def show_progress_pbar(x, pbar):\n",
    "        global print_initial\n",
    "\n",
    "        f = compute_quality_all(x)\n",
    "\n",
    "        if print_initial:\n",
    "            print(f\"initial quality = {-f:.2f}, initial x = {x}\")\n",
    "            print_initial = False\n",
    "\n",
    "        pbar.set_description(f\"current quality = {-f:.2f}, x = {x}\")\n",
    "        pbar.update(1)\n",
    "    \n",
    "    \n",
    "    pbar_for_random_iter = tqdm(range(0, number_random_iter))\n",
    "    \n",
    "    optimal_g_stat = sys.maxsize # большое положительное число\n",
    "    optimal_weights = []\n",
    "    for ri in pbar_for_random_iter:\n",
    "        pbar_for_random_iter.set_postfix({'random_iter #': ri+1})\n",
    "        random_initial_weights = np.random.uniform(0.0, 0.5, len(metrics))\n",
    "        if len(random_initial_weights) > 1:\n",
    "            random_initial_weights /= np.sum(random_initial_weights)\n",
    "        \n",
    "        print_initial = True\n",
    "        show_minimize_progress = partial(show_progress_pbar, pbar=tqdm(total=max_minimize_iter))\n",
    "        result = minimize(compute_quality_all, random_initial_weights, bounds=[(0, 1)]*len(metrics), method='nelder-mead',\n",
    "                          options={'return_all': True, 'maxiter': max_minimize_iter}, callback=show_minimize_progress)\n",
    "        negative_g_stat = compute_quality_all(result.x)\n",
    "        if negative_g_stat < optimal_g_stat:\n",
    "            optimal_g_stat = negative_g_stat\n",
    "            optimal_weights = result.x\n",
    "\n",
    "    return optimal_weights\n",
    "\n",
    "\n",
    "def calc_quality_metrics_for_optimal_combination(metrics, cyclone_events, optimal_weights, window):\n",
    "    contigency_table = compute_contigency_table(optimal_weights, metrics, cyclone_events, window)\n",
    "    g_stat, _, _ = perform_g_test(contigency_table)\n",
    "    quality_tau_n = get_tau_n_quality(contigency_table)\n",
    "    tpr, fpr, f1, bacc, mcc = compute_tpr_fpr_f1_bacc_mcc(contigency_table)\n",
    "    return contigency_table, tpr, fpr, g_stat, f1, bacc, mcc, quality_tau_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29f1b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration_by_metrics(cyclone_events, base_metric, metrics_list, suff, window, number_random_iter, quality_opt_func, autosave=False, path=''):\n",
    "    result_dict = {}\n",
    "    metrics_rating = {str(key): [] for key in metrics_list}\n",
    "    ind = 0\n",
    "    for sub_metrics_list in metrics_list:\n",
    "        print('\\n', sub_metrics_list)\n",
    "        considered_metrics = [base_metric] + [f'{m}_{suff}' for m in sub_metrics_list]\n",
    "        considered_metrics = get_full_names_for_metric(considered_metrics)\n",
    "        print(considered_metrics)\n",
    "        \n",
    "        metrics = special_loading_of_metrics(config, considered_metrics)\n",
    "\n",
    "        optimal_weights = optimization(metrics, cyclone_events, window, quality_opt_func, number_random_iter)\n",
    "        contigency_table, tpr, fpr, g_stat, f1, bacc, mcc, quality_tau_n = \\\n",
    "            calc_quality_metrics_for_optimal_combination(metrics, cyclone_events, optimal_weights, window)\n",
    "        result_dict[f'subset{ind}'] = [\n",
    "            considered_metrics, \n",
    "            optimal_weights.tolist(), \n",
    "            contigency_table.tolist(), \n",
    "            tpr, fpr, g_stat, f1, bacc, mcc, quality_tau_n\n",
    "        ]\n",
    "\n",
    "        metrics_rating[str(sub_metrics_list)] = quality_tau_n #g_stat\n",
    "        \n",
    "        if autosave:\n",
    "            f = open(f'{path}/temp_file.txt','w')\n",
    "            f.write(str(result_dict))\n",
    "            f.close()\n",
    "            \n",
    "        ind += 1\n",
    "    \n",
    "    return result_dict, metrics_rating\n",
    "\n",
    "\n",
    "def save_optimization_results(result_dict, file_name):\n",
    "    writer = ExcelWriter(file_name)\n",
    "    \n",
    "    for key in result_dict:\n",
    "        result_df = pd.DataFrame(np.array(result_dict[key], dtype=object).reshape(1, len(result_dict[key])),\n",
    "                                 columns=['metrics_subset', 'weights', 'CT', 'TPR', 'FPR', 'g_stat', 'f1', 'bacc', 'mcc', 'quality_tau_n'],\n",
    "                                dtype=object)\n",
    "        result_df.to_excel(writer, sheet_name=key, index=False)\n",
    "    \n",
    "    writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1deacc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb6271c22df45d7902259badd642c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d6e505567746958ade65951e51ecb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MIKE_L~1\\AppData\\Local\\Temp/ipykernel_21020/3334971851.py\u001b[0m in \u001b[0;36miteration_by_metrics\u001b[1;34m(cyclone_events, base_metric, metrics_list, suff, window, number_random_iter, quality_opt_func, autosave, path)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecial_loading_of_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsidered_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moptimal_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcyclone_events\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquality_opt_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_random_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mcontigency_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_stat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbacc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquality_tau_n\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mcalc_quality_metrics_for_optimal_combination\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcyclone_events\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimal_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MIKE_L~1\\AppData\\Local\\Temp/ipykernel_21020/4259382363.py\u001b[0m in \u001b[0;36moptimization\u001b[1;34m(metrics, cyclone_events, window, quality_opt_func, number_random_iter, max_minimize_iter)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mprint_initial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mshow_minimize_progress\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_progress_pbar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_minimize_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         result = minimize(compute_quality_all, random_initial_weights, bounds=[(0, 1)]*len(metrics), method='nelder-mead',\n\u001b[0m\u001b[0;32m    176\u001b[0m                           options={'return_all': True, 'maxiter': max_minimize_iter}, callback=show_minimize_progress)\n\u001b[0;32m    177\u001b[0m         \u001b[0mnegative_g_stat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_quality_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                                        \u001b[0mx_fixed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                                        remove=1)\n\u001b[1;32m--> 666\u001b[1;33m         \u001b[0mbounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nelder-mead'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mstandardize_bounds\u001b[1;34m(bounds, x0, meth)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'trust-constr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'powell'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nelder-mead'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'new'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m             \u001b[0mlb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_bound_to_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m             \u001b[0mbounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'slsqp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'old'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39\\lib\\site-packages\\scipy\\optimize\\_constraints.py\u001b[0m in \u001b[0;36mold_bound_to_new\u001b[1;34m(bounds)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \"\"\"\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mlb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;31m# Convert occurrences of None to -inf or inf, and replace occurrences of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "number_random_iter = 40\n",
    "\n",
    "quality_opt_func = 'tau_n_quality' # 'g_stat' or 'tau_n_quality'\n",
    "window = 1*8                       # 1*8 = 1 day; 2*8 = 2 day\n",
    "base_metric = 'MSLP_preproc'       # MSLP or MSLP_preproc\n",
    "suff = 'w'                         # 'w' or '0.9' or '0.95'\n",
    "network_metrics_1 = [['LCC'], ['degree'], ['closeness'], ['EVC']]\n",
    "\n",
    "\n",
    "cyclone_events = np.load('../cyclones_events.npz')['cyclone_events_2'] # track_size = 2 - для любого размера окна \n",
    "                                                                    # результаты одинаковые, т.к. важен только тот факт, \n",
    "                                                                    # что циклон где-то был в конкретный момент времени\n",
    "\n",
    "global_path = config.event_predictions_options['work_dir'] / config.event_predictions_options['output_predictions_1d']\n",
    "\n",
    "folder = f'{base_metric}_metrics_{suff}_{int(window/8)}m8w'\n",
    "path = f'{global_path}/{folder}'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    \n",
    "# Only base_metric\n",
    "file_name = f'{path}/ep1D_{base_metric}_{int(window/8)}m8w.xlsx'\n",
    "result_dict, _ = iteration_by_metrics(cyclone_events, base_metric, [''], '', window, number_random_iter, quality_opt_func)\n",
    "print(result_dict)\n",
    "save_optimization_results(result_dict, file_name)\n",
    "\n",
    "# MSLP + one metric\n",
    "file_name = f'{path}/ep1D_{base_metric}_1metric_{suff}_{int(window/8)}m8w.xlsx'\n",
    "result_dict, metrics_rating = iteration_by_metrics(cyclone_events, base_metric, network_metrics_1, suff, window, \n",
    "                                                   number_random_iter, quality_opt_func, True, path)\n",
    "print(result_dict)\n",
    "save_optimization_results(result_dict, file_name)\n",
    "\n",
    "# MSLP + metrics\n",
    "file_name = f'{path}/ep1D_{base_metric}_metrics_{suff}_{int(window/8)}m8w.xlsx'\n",
    "metrics_priority = sorted(metrics_rating, key=metrics_rating.get, reverse=True)\n",
    "metrics_priority = [eval(m)[0] for m in metrics_priority]\n",
    "pd.DataFrame({'metrics_priority': metrics_priority}).to_csv(f'{file_name.split(\".xlsx\")[0]}_metrics_order.txt', index=False)\n",
    "print('metrics_priority:', metrics_priority)\n",
    "network_metrics_2 = [metrics_priority[0:2+i] for i in range(0, len(metrics_priority)-1)]\n",
    "print(network_metrics_2)\n",
    "result_dict, _ = iteration_by_metrics(cyclone_events, base_metric, network_metrics_2, suff, window, \n",
    "                                      number_random_iter, quality_opt_func, True, path)\n",
    "print(result_dict)\n",
    "save_optimization_results(result_dict, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb4d6d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('Z:/Research/Climate/data/ERA5/ERA5_MSL_1982_2020_3h_0.75/event_detection_window_2d_delay_0d/predictions_1d')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:15:42) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8571e7f3e92f6e490cddd84ef78d4e4e0b96a1f565959148b10a39523fba88f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
